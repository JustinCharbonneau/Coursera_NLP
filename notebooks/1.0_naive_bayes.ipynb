{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "\n",
    "### Recap - Conditional Probabilities\n",
    "\n",
    "P(A|B) = P(A and B)/P(B)  \n",
    "\n",
    "P(A|B) = P(B|A)/P(B)*P(A)  \n",
    "OR  \n",
    "P(A|B) = P(B|A) * P(A)/P(B)  \n",
    "\n",
    "### Summary\n",
    "\n",
    "This technique is very simple to use and runs prety fast.  \n",
    "It offers good baselines on easy tasks such as sentiment analysis.  \n",
    "More time needs to be spent on the feature representation of the data, such as BOW, TF-IDF, etc.  \n",
    "  \n",
    "### Additional Resources\n",
    "- Week 2 of Natural Language Processing with Classification and Vector Spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('../data/processed/imdb_dataset.parquet')\n",
    "train_df = df[df['role']=='train']\n",
    "test_df = df[df['role']=='test']\n",
    "del df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple BOW with vocab = 20k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39964, 3)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=20000)\n",
    "train_x = cv.fit_transform(train_df['review'])\n",
    "test_x = cv.transform(test_df['review'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pd.DataFrame(train_x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultinomialNB().fit(train_x, train_df['sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541251494619371"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_df['sentiment'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple BOW with ngrams = 4 and vocab = 20k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features=20000, ngram_range=(1,4))\n",
    "train_x = cv.fit_transform(train_df['review'])\n",
    "test_x = cv.transform(test_df['review'])\n",
    "train_x = pd.DataFrame(train_x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8675767237943404"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB().fit(train_x, train_df['sentiment'])\n",
    "y_pred = model.predict(test_x)\n",
    "accuracy_score(test_df['sentiment'], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple TF-IDF with ngrams = 4 and covab 20k\n",
    "\n",
    "TF-IDF is used to penalize words that are too often in the different classes. For example, this might penalize movie titles, that are not part of the stopwords. \n",
    "\n",
    "In addition, we often use the log of TF-IDF because ... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(max_features=20000, ngram_range=(1,4))\n",
    "train_x = cv.fit_transform(train_df['review'])\n",
    "test_x = cv.transform(test_df['review'])\n",
    "train_x = pd.DataFrame(train_x.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8764447987245915"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MultinomialNB().fit(train_x, train_df['sentiment'])\n",
    "y_pred = model.predict(test_x)\n",
    "accuracy_score(test_df['sentiment'], y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
